"""
ðŸŽ¬ AI_MODULE: VideoStudioAPI
ðŸŽ¬ AI_DESCRIPTION: FastAPI endpoints per video studio
ðŸŽ¬ AI_BUSINESS: Espone API per workflow video, pose detection, traduzione, avatar creation
ðŸŽ¬ AI_TEACHING: FastAPI, file upload, async processing, WebSocket real-time updates

ðŸ”„ ALTERNATIVE_VALUTATE:
- Flask: Scartato per meno features automatiche
- Django REST: Scartato per overhead eccessivo
- gRPC: Scartato per complessitÃ  frontend

ðŸ’¡ PERCHÃ‰_QUESTA_SOLUZIONE:
- FastAPI: Type hints, auto-docs, async support, file upload
- WebSocket: Real-time progress updates
- Background tasks: Processing asincrono
- Pydantic: Validation automatica

ðŸ“Š METRICHE_SUCCESSO:
- Upload time: <30s per 100MB
- Processing time: <50% tempo originale
- API uptime: 99.9%
- Error rate: <2%

ðŸ—ï¸ STRUTTURA LEGO:
- INPUT: Video files, configuration, user preferences
- OUTPUT: Processed videos, progress updates, analysis results
- DIPENDENZE: FastAPI, WebSocket, workflow_orchestrator
- USATO DA: Web Frontend, Mobile App

ðŸŽ¯ RAG_METADATA:
- Tags: fastapi, video-processing, websocket, file-upload, ai
- Categoria: Video Studio API
- Versione: 1.0.0

TRAINING_PATTERNS:
- Success: Video processed with quality output
- Failure: Error handling with recovery options
- Feedback: Real-time progress and quality metrics
"""

from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, Form, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel, Field
from typing import Optional, Dict, List, Any
import logging
import uvicorn
import asyncio
import json
from datetime import datetime

# Import Ingest Orchestrator
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))
from ingest_orchestrator import IngestOrchestrator, IngestMetadata, ProcessingOptions, AssetType, ProcessingPreset
from pathlib import Path
import uuid

from workflow_orchestrator import WorkflowOrchestrator, WorkflowConfig, WorkflowStage

# Import Projects API
from api.projects import router as projects_router
from api.massive_processing import router as massive_processing_router

# Import Parallel Processing (NUOVO!)
try:
    from api.massive_processing_PARALLELO import router as massive_processing_parallel_router
    PARALLEL_AVAILABLE = True
except ImportError:
    PARALLEL_AVAILABLE = False
    logger.warning("Parallel processing endpoints not available (file not found)")

logger = logging.getLogger(__name__)

# Pydantic models
class WorkflowRequest(BaseModel):
    """Richiesta avvio workflow"""
    stages: List[str] = Field(..., description="Lista stages da eseguire")
    quality_preset: str = Field("high", description="Preset qualitÃ ")
    parallel_workers: int = Field(4, description="Numero worker paralleli")
    timeout_minutes: int = Field(60, description="Timeout in minuti")
    user_preferences: Dict[str, Any] = Field(default_factory=dict, description="Preferenze utente")

class WorkflowStatusResponse(BaseModel):
    """Risposta status workflow"""
    id: str
    status: str
    current_stage: str
    progress: float
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    checkpoints: Dict[str, Any] = Field(default_factory=dict)

class ProcessingResultResponse(BaseModel):
    """Risposta risultato elaborazione"""
    success: bool
    message: str
    workflow_id: Optional[str] = None
    output_url: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

class WebSocketManager:
    """Manager per connessioni WebSocket"""
    
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, websocket: WebSocket, client_id: str):
        """Connette client WebSocket"""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket connected: {client_id}")
    
    def disconnect(self, client_id: str):
        """Disconnette client WebSocket"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket disconnected: {client_id}")
    
    async def send_progress(self, client_id: str, data: Dict[str, Any]):
        """Invia aggiornamento progresso"""
        if client_id in self.active_connections:
            try:
                websocket = self.active_connections[client_id]
                await websocket.send_text(json.dumps(data))
            except Exception as e:
                logger.error(f"Error sending WebSocket message: {e}")
                self.disconnect(client_id)
    
    async def broadcast_progress(self, data: Dict[str, Any]):
        """Broadcast progresso a tutti i client"""
        disconnected = []
        for client_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(json.dumps(data))
            except Exception as e:
                logger.error(f"Error broadcasting to {client_id}: {e}")
                disconnected.append(client_id)
        
        # Rimuovi client disconnessi
        for client_id in disconnected:
            self.disconnect(client_id)

def create_video_studio_app(config: Dict[str, Any]) -> FastAPI:
    """
    Crea FastAPI app per video studio
    
    Args:
        config: Configurazione servizio
        
    Returns:
        FastAPI app configurata
    """
    app = FastAPI(
        title="MediaCenter Video Studio API",
        description="API per elaborazione video, pose detection e avatar creation",
        version="1.0.0",
        docs_url="/docs",
        redoc_url="/redoc"
    )
    
    # CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=[
            "http://localhost:3000",
            "http://localhost:3100",  # Frontend attivo su questa porta
            "http://127.0.0.1:3000",
            "http://127.0.0.1:3100",
            "*"  # Fallback per development
        ],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    logger.info("âœ… CORS configured for localhost:3000, localhost:3100, and *")
    
    # Include Projects API router
    app.include_router(projects_router, prefix="/api/studio", tags=["projects"])
    
    # Include Massive Processing API router
    app.include_router(massive_processing_router, prefix="/api/studio", tags=["massive-processing"])
    
    # Include Parallel Processing API router (NUOVO!)
    if PARALLEL_AVAILABLE:
        app.include_router(massive_processing_parallel_router, prefix="/api/studio", tags=["massive-processing-parallel"])
        logger.info("âœ… Parallel processing endpoints loaded")
    
    # Inizializza servizi
    orchestrator = WorkflowOrchestrator(config)
    websocket_manager = WebSocketManager()
    
    # Inizializza ingest orchestrator
    ingest_orchestrator = IngestOrchestrator()
    
    # File upload directory
    upload_dir = Path(config.get('upload_dir', './uploads'))
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    @app.post("/workflow/start", response_model=ProcessingResultResponse)
    async def start_workflow(
        file: UploadFile = File(..., description="Video file da processare"),
        stages: str = Form(..., description="Lista stages separati da virgola"),
        quality_preset: str = Form("high"),
        parallel_workers: int = Form(4),
        timeout_minutes: int = Form(60),
        user_preferences: str = Form("{}")
    ):
        """
        Avvia workflow di elaborazione video
        
        Args:
            file: File video da caricare
            stages: Lista stages da eseguire
            quality_preset: Preset qualitÃ 
            parallel_workers: Numero worker paralleli
            timeout_minutes: Timeout in minuti
            user_preferences: Preferenze utente (JSON)
            
        Returns:
            Risposta con ID workflow
        """
        try:
            # Validazione file
            if not file.filename:
                raise HTTPException(status_code=400, detail="No file provided")
            
            # Controlla formato file
            allowed_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
            file_ext = Path(file.filename).suffix.lower()
            if file_ext not in allowed_extensions:
                raise HTTPException(
                    status_code=400, 
                    detail=f"File format not supported. Allowed: {allowed_extensions}"
                )
            
            # Salva file upload
            file_id = str(uuid.uuid4())
            upload_path = upload_dir / f"{file_id}{file_ext}"
            
            with open(upload_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            # Parse stages
            stage_names = [s.strip() for s in stages.split(',')]
            workflow_stages = []
            
            for stage_name in stage_names:
                try:
                    stage = WorkflowStage(stage_name)
                    workflow_stages.append(stage)
                except ValueError:
                    raise HTTPException(
                        status_code=400,
                        detail=f"Invalid stage: {stage_name}"
                    )
            
            # Parse user preferences
            try:
                preferences = json.loads(user_preferences)
            except json.JSONDecodeError:
                preferences = {}
            
            # Crea configurazione workflow
            workflow_config = WorkflowConfig(
                input_path=str(upload_path),
                output_dir=str(config.get('output_dir', './output')),
                stages_enabled=workflow_stages,
                quality_preset=quality_preset,
                parallel_workers=parallel_workers,
                timeout_minutes=timeout_minutes,
                user_preferences=preferences
            )
            
            # Avvia workflow
            workflow_id = await orchestrator.start_workflow(workflow_config)
            
            logger.info(f"Workflow started: {workflow_id} for file: {file.filename}")
            
            return ProcessingResultResponse(
                success=True,
                message="Workflow avviato con successo",
                workflow_id=workflow_id,
                metadata={
                    'filename': file.filename,
                    'file_size': len(content),
                    'stages': stage_names,
                    'quality_preset': quality_preset
                }
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error starting workflow: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.get("/workflow/{workflow_id}/status", response_model=WorkflowStatusResponse)
    async def get_workflow_status(workflow_id: str):
        """
        Ottiene status workflow
        
        Args:
            workflow_id: ID workflow
            
        Returns:
            Status workflow
        """
        try:
            status_data = await orchestrator.get_workflow_status(workflow_id)
            
            if not status_data:
                raise HTTPException(status_code=404, detail="Workflow non trovato")
            
            return WorkflowStatusResponse(**status_data)
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error getting workflow status: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.delete("/workflow/{workflow_id}")
    async def cancel_workflow(workflow_id: str):
        """
        Cancella workflow
        
        Args:
            workflow_id: ID workflow
            
        Returns:
            Risposta successo
        """
        try:
            success = await orchestrator.cancel_workflow(workflow_id)
            
            if not success:
                raise HTTPException(status_code=500, detail="Errore cancellazione workflow")
            
            return {"success": True, "message": "Workflow cancellato con successo"}
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error cancelling workflow: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.get("/workflow/{workflow_id}/download")
    async def download_result(workflow_id: str):
        """
        Download risultato workflow
        
        Args:
            workflow_id: ID workflow
            
        Returns:
            File risultato
        """
        try:
            status_data = await orchestrator.get_workflow_status(workflow_id)
            
            if not status_data:
                raise HTTPException(status_code=404, detail="Workflow non trovato")
            
            if status_data['status'] != 'completed':
                raise HTTPException(status_code=400, detail="Workflow non completato")
            
            # Cerca file output nei checkpoints
            output_path = None
            checkpoints = status_data.get('checkpoints', {})
            
            for stage, checkpoint in checkpoints.items():
                if checkpoint.get('metadata', {}).get('output_path'):
                    output_path = checkpoint['metadata']['output_path']
                    break
            
            if not output_path or not Path(output_path).exists():
                raise HTTPException(status_code=404, detail="File risultato non trovato")
            
            return FileResponse(
                path=output_path,
                filename=f"{workflow_id}_result.mp4",
                media_type="video/mp4"
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Error downloading result: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.websocket("/ws/{workflow_id}")
    async def websocket_endpoint(websocket: WebSocket, workflow_id: str):
        """
        WebSocket endpoint per aggiornamenti real-time
        
        Args:
            websocket: WebSocket connection
            workflow_id: ID workflow da monitorare
        """
        client_id = f"{workflow_id}_{uuid.uuid4().hex[:8]}"
        
        try:
            await websocket_manager.connect(websocket, client_id)
            
            # Loop per inviare aggiornamenti
            while True:
                try:
                    # Ottieni status workflow
                    status_data = await orchestrator.get_workflow_status(workflow_id)
                    
                    if not status_data:
                        await websocket_manager.send_progress(client_id, {
                            "error": "Workflow non trovato"
                        })
                        break
                    
                    # Invia aggiornamento
                    await websocket_manager.send_progress(client_id, {
                        "workflow_id": workflow_id,
                        "status": status_data['status'],
                        "current_stage": status_data['current_stage'],
                        "progress": status_data['progress'],
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    # Se completato o fallito, esci
                    if status_data['status'] in ['completed', 'failed', 'cancelled']:
                        break
                    
                    # Attendi prima del prossimo aggiornamento
                    await asyncio.sleep(2)
                    
                except WebSocketDisconnect:
                    break
                except Exception as e:
                    logger.error(f"WebSocket error: {e}")
                    await websocket_manager.send_progress(client_id, {
                        "error": str(e)
                    })
                    break
                    
        except WebSocketDisconnect:
            pass
        except Exception as e:
            logger.error(f"WebSocket connection error: {e}")
        finally:
            websocket_manager.disconnect(client_id)
    
    @app.get("/workflows", response_model=List[WorkflowStatusResponse])
    async def list_workflows(limit: int = 50, offset: int = 0):
        """
        Lista workflows
        
        Args:
            limit: Numero massimo risultati
            offset: Offset per paginazione
            
        Returns:
            Lista workflows
        """
        try:
            # Implementazione semplificata - in produzione usare query piÃ¹ complessa
            cursor = orchestrator.conn.cursor()
            cursor.execute("""
                SELECT * FROM workflows 
                ORDER BY created_at DESC 
                LIMIT ? OFFSET ?
            """, (limit, offset))
            
            workflows = []
            for row in cursor.fetchall():
                workflow_data = {
                    'id': row['id'],
                    'status': row['status'],
                    'current_stage': row['current_stage'],
                    'progress': row['progress'],
                    'started_at': row['started_at'],
                    'completed_at': row['completed_at'],
                    'error_message': row['error_message'],
                    'metadata': json.loads(row['metadata_json']) if row['metadata_json'] else {},
                    'checkpoints': json.loads(row['checkpoints_json']) if row['checkpoints_json'] else {}
                }
                workflows.append(WorkflowStatusResponse(**workflow_data))
            
            return workflows
            
        except Exception as e:
            logger.error(f"Error listing workflows: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.get("/workflow/{workflow_id}/logs")
    async def get_workflow_logs(workflow_id: str, limit: int = 100):
        """
        Ottiene logs workflow
        
        Args:
            workflow_id: ID workflow
            limit: Numero massimo logs
            
        Returns:
            Lista logs
        """
        try:
            cursor = orchestrator.conn.cursor()
            cursor.execute("""
                SELECT * FROM workflow_logs 
                WHERE workflow_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            """, (workflow_id, limit))
            
            logs = []
            for row in cursor.fetchall():
                logs.append({
                    'id': row['id'],
                    'stage': row['stage'],
                    'level': row['level'],
                    'message': row['message'],
                    'timestamp': row['timestamp']
                })
            
            return {"logs": logs}
            
        except Exception as e:
            logger.error(f"Error getting workflow logs: {e}")
            raise HTTPException(status_code=500, detail=f"Errore interno: {str(e)}")
    
    @app.get("/stages")
    async def get_available_stages():
        """
        Ottiene stages disponibili
        
        Returns:
            Lista stages disponibili
        """
        stages = []
        for stage in WorkflowStage:
            if stage not in [WorkflowStage.INITIALIZED, WorkflowStage.COMPLETED, WorkflowStage.FAILED]:
                stages.append({
                    'name': stage.value,
                    'description': f"Stage {stage.value}",
                    'enabled': True
                })
        
        return {"stages": stages}
    
    @app.get("/health")
    @app.options("/health")
    async def health_check():
        """
        Health check endpoint
        
        Returns:
            Status servizio
        """
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "service": "video_studio",
            "version": "1.0.0",
            "active_workflows": len(orchestrator.active_workflows)
        }
    
    @app.get("/api/studio/stats")
    async def get_studio_stats():
        """Get studio statistics"""
        try:
            # Simula statistiche reali
            return {
                "voice_models": 3,
                "processing_jobs": 2,
                "completed_workflows": 8,
                "active_workflows": 1
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error getting stats: {str(e)}")
    
    @app.post("/api/studio/pose-analysis")
    async def pose_analysis(
        video: UploadFile = File(...),
        analysis_type: str = Form("pose_detection"),
        extract_skeletons: str = Form("true")
    ):
        """Analyze video for REAL pose detection and skeleton extraction"""
        try:
            # Salva video temporaneo
            temp_video_path = orchestrator.temp_dir / f"pose_analysis_{int(time.time())}.mp4"
            
            with open(temp_video_path, "wb") as buffer:
                content = await video.read()
                buffer.write(content)
            
            # Importa e usa MotionAnalyzer REALE
            from motion_analyzer import MotionAnalyzer
            
            motion_analyzer = MotionAnalyzer()
            
            # Analisi REALE con motion analyzer
            result = await motion_analyzer.analyze_video(str(temp_video_path))
            
            # Pulisci file temporaneo
            temp_video_path.unlink()
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Pose analysis failed: {str(e)}")
    
    @app.post("/api/studio/voice-cloning")
    async def voice_cloning(
        video: UploadFile = File(...),
        speaker_name: str = Form("User Voice"),
        text_sample: str = Form("")
    ):
        """Clone voice from video"""
        try:
            # Simula voice cloning
            voice_id = f"voice_{int(time.time())}"
            
            result = {
                "success": True,
                "voice_id": voice_id,
                "model_path": f"/models/{voice_id}.pth",
                "quality_score": 0.95,
                "speaker_name": speaker_name,
                "processing_time": "45.2"
            }
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Voice cloning failed: {str(e)}")
    
    @app.post("/api/studio/annotate")
    async def annotate_techniques(
        video: UploadFile = File(...),
        technique_type: str = Form("martial_arts")
    ):
        """Annotate martial arts techniques in video"""
        try:
            # Salva video temporaneo
            temp_video_path = orchestrator.temp_dir / f"annotation_{int(time.time())}.mp4"
            
            with open(temp_video_path, "wb") as buffer:
                content = await video.read()
                buffer.write(content)
            
            # Importa e usa AnnotationSystem REALE
            from annotation_system import AnnotationSystem
            
            annotation_system = AnnotationSystem()
            
            # Annotazione REALE
            result = await annotation_system.annotate_video(str(temp_video_path))
            
            # Pulisci file temporaneo
            temp_video_path.unlink()
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Annotation failed: {str(e)}")
    
    @app.post("/api/studio/compare")
    async def compare_techniques(
        video1: UploadFile = File(...),
        video2: UploadFile = File(...)
    ):
        """Compare martial arts techniques between two videos"""
        try:
            # Salva video temporanei
            temp_video1_path = orchestrator.temp_dir / f"compare1_{int(time.time())}.mp4"
            temp_video2_path = orchestrator.temp_dir / f"compare2_{int(time.time())}.mp4"
            
            with open(temp_video1_path, "wb") as buffer:
                content = await video1.read()
                buffer.write(content)
            
            with open(temp_video2_path, "wb") as buffer:
                content = await video2.read()
                buffer.write(content)
            
            # Importa e usa ComparisonEngine REALE
            from comparison_engine import ComparisonEngine
            
            comparison_engine = ComparisonEngine()
            
            # Confronto REALE
            result = await comparison_engine.compare_videos(str(temp_video1_path), str(temp_video2_path))
            
            # Pulisci file temporanei
            temp_video1_path.unlink()
            temp_video2_path.unlink()
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Comparison failed: {str(e)}")
    
    @app.post("/api/studio/text-to-speech")
    async def text_to_speech(
        text: str = Form(...),
        voice_model: str = Form(...),
        language: str = Form("en")
    ):
        """Convert text to speech using cloned voice"""
        try:
            # Simula TTS
            audio_id = f"tts_{int(time.time())}"
            
            result = {
                "success": True,
                "audio_id": audio_id,
                "audio_url": f"/audio/{audio_id}.wav",
                "duration": len(text) * 0.1,
                "language": language
            }
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Text-to-speech failed: {str(e)}")
    
    # ============= TRANSLATION ENDPOINTS =============
    
    @app.post("/api/studio/translate")
    async def translate_text(
        text: str = Form(...),
        source_lang: str = Form("auto"),
        target_lang: str = Form(...),
        use_martial_dictionary: bool = Form(True),
        multi_engine: bool = Form(False)
    ):
        """
        Traduci testo usando HybridTranslator
        
        Supporta:
        - Auto-detect lingua sorgente
        - Dizionario arti marziali
        - Multi-engine per massima qualitÃ 
        """
        try:
            from hybrid_translator import HybridTranslator
            
            translator = HybridTranslator()
            
            result = translator.translate(
                text,
                src_lang=source_lang,
                dest_lang=target_lang,
                apply_dictionary=use_martial_dictionary,
                multi_engine=multi_engine
            )
            
            return {
                "success": True,
                "original_text": text,
                "translated_text": result['text'],
                "source_lang": result.get('detected_lang', source_lang),
                "target_lang": target_lang,
                "confidence": result.get('confidence', 0),
                "engine": result.get('engine', 'hybrid'),
                "alternatives": result.get('alternatives', [])
            }
            
        except Exception as e:
            logger.error(f"Translation failed: {e}")
            raise HTTPException(status_code=500, detail=f"Translation failed: {str(e)}")
    
    @app.post("/api/studio/translate/batch")
    async def translate_batch(
        texts: List[str] = Form(...),
        source_lang: str = Form("auto"),
        target_lang: str = Form(...),
        use_martial_dictionary: bool = Form(True)
    ):
        """
        Traduci batch di testi
        """
        try:
            from hybrid_translator import HybridTranslator
            
            translator = HybridTranslator()
            
            results = []
            for text in texts:
                result = translator.translate(
                    text,
                    src_lang=source_lang,
                    dest_lang=target_lang,
                    apply_dictionary=use_martial_dictionary
                )
                results.append({
                    "original": text,
                    "translated": result['text'],
                    "confidence": result.get('confidence', 0)
                })
            
            return {
                "success": True,
                "translations": results,
                "total": len(results)
            }
            
        except Exception as e:
            logger.error(f"Batch translation failed: {e}")
            raise HTTPException(status_code=500, detail=f"Batch translation failed: {str(e)}")
    
    @app.get("/api/studio/translate/languages")
    async def get_supported_languages():
        """
        Ottieni lingue supportate per traduzione
        """
        try:
            return {
                "success": True,
                "languages": {
                    "it": "Italian",
                    "en": "English",
                    "es": "Spanish",
                    "fr": "French",
                    "de": "German",
                    "pt": "Portuguese",
                    "zh": "Chinese",
                    "ja": "Japanese",
                    "ko": "Korean",
                    "ar": "Arabic",
                    "ru": "Russian"
                },
                "auto_detect": True,
                "martial_dictionary": True
            }
            
        except Exception as e:
            logger.error(f"Get languages failed: {e}")
            raise HTTPException(status_code=500, detail=f"Get languages failed: {str(e)}")
    
    @app.post("/api/studio/translate/correct")
    async def correct_translation(
        original_text: str = Form(...),
        machine_translation: str = Form(...),
        corrected_translation: str = Form(...),
        source_lang: str = Form(...),
        target_lang: str = Form(...)
    ):
        """
        Salva correzione manuale per apprendimento sistema
        """
        try:
            # Qui integreremo TranslationCorrectionSystem
            # Per ora salviamo in un file JSON
            from pathlib import Path
            import json
            from datetime import datetime
            
            corrections_file = Path("./data/translation_corrections.json")
            corrections_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Carica correzioni esistenti
            corrections = []
            if corrections_file.exists():
                with open(corrections_file, 'r', encoding='utf-8') as f:
                    corrections = json.load(f)
            
            # Aggiungi nuova correzione
            corrections.append({
                "original_text": original_text,
                "machine_translation": machine_translation,
                "corrected_translation": corrected_translation,
                "source_lang": source_lang,
                "target_lang": target_lang,
                "timestamp": datetime.now().isoformat()
            })
            
            # Salva
            with open(corrections_file, 'w', encoding='utf-8') as f:
                json.dump(corrections, f, ensure_ascii=False, indent=2)
            
            return {
                "success": True,
                "message": "Correction saved for learning",
                "total_corrections": len(corrections)
            }
            
        except Exception as e:
            logger.error(f"Save correction failed: {e}")
            raise HTTPException(status_code=500, detail=f"Save correction failed: {str(e)}")
    
    # ============= INGEST ENDPOINTS =============
    
    @app.post("/api/ingest")
    async def ingest_asset(
        files: List[UploadFile] = File(...),
        asset_type: str = Form(...),
        language: str = Form("auto"),
        source: str = Form(""),
        rights_accepted: bool = Form(False),
        cite_source: bool = Form(False),
        group_id: Optional[str] = Form(None),
        tags: str = Form(""),
        author: str = Form(""),
        title: str = Form(""),
        preset: str = Form("standard"),
        target_languages: str = Form("it,en"),
        confidence_threshold: float = Form(0.65),
        use_martial_dictionary: bool = Form(True),
        save_clips: bool = Form(True),
        import_as_skeleton: bool = Form(False),
        build_voice_model: bool = Form(False),
        export_format: str = Form("bvh"),
        priority: str = Form("normal")
    ):
        """
        Ingest unificato per video/audio/PDF/immagini/skeleton
        
        Unico punto di ingresso per tutti i contenuti multimediali.
        Evita duplicati e sovrapposizioni, gestisce pipeline asincrone.
        """
        try:
            # Valida tipo asset
            try:
                asset_type_enum = AssetType(asset_type.lower())
            except ValueError:
                raise HTTPException(status_code=400, detail=f"Invalid asset type: {asset_type}")
            
            # Valida preset
            try:
                preset_enum = ProcessingPreset(preset.lower())
            except ValueError:
                raise HTTPException(status_code=400, detail=f"Invalid preset: {preset}")
            
            # Crea metadata
            metadata = IngestMetadata(
                type=asset_type_enum,
                language=language,
                source=source,
                rights_accepted=rights_accepted,
                cite_source=cite_source,
                group_id=group_id,
                tags=tags.split(",") if tags else [],
                author=author,
                title=title
            )
            
            # Crea opzioni processing
            options = ProcessingOptions(
                preset=preset_enum,
                knowledge={
                    "enabled": preset_enum in [ProcessingPreset.STANDARD, ProcessingPreset.KNOWLEDGE],
                    "target_languages": target_languages.split(",") if target_languages else ["it", "en"],
                    "confidence_threshold": confidence_threshold,
                    "use_martial_dictionary": use_martial_dictionary
                },
                techniques={
                    "enabled": preset_enum in [ProcessingPreset.STANDARD, ProcessingPreset.STAGE],
                    "save_clips": save_clips
                },
                skeleton={
                    "enabled": preset_enum in [ProcessingPreset.STANDARD, ProcessingPreset.SKELETON, ProcessingPreset.BLENDER],
                    "import_as_skeleton": import_as_skeleton
                },
                voice={
                    "enabled": preset_enum == ProcessingPreset.VOICE,
                    "build_model": build_voice_model
                },
                blender={
                    "enabled": preset_enum == ProcessingPreset.BLENDER,
                    "export_format": export_format
                },
                priority=priority
            )
            
            # Esegui ingest
            asset_id, job_id = await ingest_orchestrator.ingest_asset(files, metadata, options)
            
            return {
                "success": True,
                "asset_id": asset_id,
                "job_id": job_id,
                "message": f"Asset {asset_id} queued for processing with preset {preset}",
                "status_url": f"/api/ingest/status/{job_id}"
            }
            
        except Exception as e:
            logger.error(f"Ingest failed: {e}")
            raise HTTPException(status_code=500, detail=f"Ingest failed: {str(e)}")
    
    @app.get("/api/ingest/status/{job_id}")
    async def get_job_status(job_id: str):
        """Ottiene status di un job di processing"""
        try:
            status = ingest_orchestrator.get_job_status(job_id)
            if not status:
                raise HTTPException(status_code=404, detail="Job not found")
            
            return {
                "success": True,
                "job_id": job_id,
                "status": status['status'],
                "progress": status['progress'],
                "created_at": status['created_at'],
                "started_at": status['started_at'],
                "completed_at": status['completed_at'],
                "error_message": status['error_message']
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Status check failed: {e}")
            raise HTTPException(status_code=500, detail=f"Status check failed: {str(e)}")
    
    @app.get("/api/ingest/asset/{asset_id}")
    async def get_asset_info(asset_id: str):
        """Ottiene informazioni di un asset"""
        try:
            asset = ingest_orchestrator.get_asset_info(asset_id)
            if not asset:
                raise HTTPException(status_code=404, detail="Asset not found")
            
            return {
                "success": True,
                "asset_id": asset_id,
                "original_filename": asset['original_filename'],
                "file_type": asset['file_type'],
                "file_size": asset['file_size'],
                "created_at": asset['created_at'],
                "metadata": json.loads(asset['metadata_json']),
                "processing_options": json.loads(asset['processing_options_json']),
                "storage_path": asset['storage_path'],
                "derivatives": json.loads(asset['derivatives_json']),
                "processing_results": json.loads(asset['processing_results_json']),
                "status": asset['status']
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Asset info failed: {e}")
            raise HTTPException(status_code=500, detail=f"Asset info failed: {str(e)}")
    
    @app.get("/api/ingest/jobs")
    async def list_jobs(status: Optional[str] = None):
        """Lista job con filtro opzionale per status"""
        try:
            from ingest_orchestrator import JobStatus
            
            status_enum = None
            if status:
                try:
                    status_enum = JobStatus(status.lower())
                except ValueError:
                    raise HTTPException(status_code=400, detail=f"Invalid status: {status}")
            
            jobs = ingest_orchestrator.list_jobs(status_enum)
            
            return {
                "success": True,
                "jobs": jobs,
                "total": len(jobs)
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"List jobs failed: {e}")
            raise HTTPException(status_code=500, detail=f"List jobs failed: {str(e)}")
    
    # Skeleton & Video Viewer Endpoints
    @app.get("/api/studio/skeleton/{asset_id}")
    async def get_skeleton_data(asset_id: str):
        """Ottiene dati skeleton per visualizzazione"""
        try:
            from pathlib import Path
            import json
            
            skeleton_path = Path("storage/skeletons") / f"{asset_id}_skeleton.json"
            
            if not skeleton_path.exists():
                raise HTTPException(status_code=404, detail="Skeleton not found")
            
            with open(skeleton_path, 'r') as f:
                data = json.load(f)
            
            return data
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Skeleton retrieval failed: {e}")
            raise HTTPException(status_code=500, detail=f"Skeleton retrieval failed: {str(e)}")
    
    @app.get("/api/studio/video/{asset_id}")
    async def get_video_file(asset_id: str):
        """Serve video file per playback"""
        try:
            from pathlib import Path
            from fastapi.responses import FileResponse
            
            video_path = Path("storage/originals") / f"{asset_id}.mp4"
            
            if not video_path.exists():
                raise HTTPException(status_code=404, detail="Video not found")
            
            return FileResponse(
                path=str(video_path),
                media_type="video/mp4",
                filename=f"{asset_id}.mp4"
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Video retrieval failed: {e}")
            raise HTTPException(status_code=500, detail=f"Video retrieval failed: {str(e)}")
    
    @app.get("/api/studio/skeletons")
    async def list_skeleton_assets():
        """Lista tutti gli skeleton disponibili con metadata"""
        try:
            from pathlib import Path
            import json
            import os
            from datetime import datetime
            
            skeletons = []
            skeleton_dir = Path("../storage/skeletons")
            originals_dir = Path("../storage/originals")
            
            if not skeleton_dir.exists():
                return {"skeletons": []}
            
            # Scansiona tutti i file skeleton
            for skeleton_file in skeleton_dir.glob("*_skeleton.json"):
                try:
                    asset_id = skeleton_file.stem.replace("_skeleton", "")
                    
                    # Leggi metadata skeleton
                    with open(skeleton_file, 'r') as f:
                        skeleton_data = json.load(f)
                    
                    # Verifica se esiste il video originale
                    video_file = originals_dir / f"{asset_id}.mp4"
                    if not video_file.exists():
                        continue
                    
                    # Calcola metadata
                    total_frames = len(skeleton_data.get('frames', []))
                    avg_confidence = 0
                    duration = 0
                    
                    if skeleton_data.get('frames'):
                        confidences = [f.get('confidence', 0) for f in skeleton_data['frames']]
                        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                        duration = skeleton_data['frames'][-1].get('timestamp', 0)
                    
                    # Determina status basato su job
                    job_status = "completed"  # Default
                    try:
                        job_info = ingest_orchestrator.get_job_status(asset_id)
                        if job_info:
                            job_status = job_info.get('status', 'completed')
                    except:
                        pass
                    
                    skeleton_info = {
                        "asset_id": asset_id,
                        "filename": f"{asset_id}.mp4",
                        "created_at": datetime.fromtimestamp(skeleton_file.stat().st_mtime).isoformat(),
                        "duration": duration,
                        "total_frames": total_frames,
                        "avg_confidence": avg_confidence,
                        "thumbnail_url": f"/api/studio/thumbnail/{asset_id}",  # Placeholder
                        "video_url": f"/api/studio/video/{asset_id}",
                        "skeleton_url": f"/api/studio/skeleton/{asset_id}",
                        "status": job_status
                    }
                    
                    skeletons.append(skeleton_info)
                    
                except Exception as e:
                    logger.warning(f"Error processing skeleton {skeleton_file}: {e}")
                    continue
            
            # Ordina per data di creazione (piÃ¹ recenti prima)
            skeletons.sort(key=lambda x: x['created_at'], reverse=True)
            
            return {"skeletons": skeletons}
            
        except Exception as e:
            logger.error(f"Skeleton listing failed: {e}")
            raise HTTPException(status_code=500, detail=f"Skeleton listing failed: {str(e)}")
    
    @app.get("/api/studio/debug/skeleton/{asset_id}")
    async def debug_skeleton_path(asset_id: str):
        """Debug endpoint per verificare i path skeleton"""
        try:
            from pathlib import Path
            
            # Testa diversi path
            paths_to_test = [
                Path("storage/skeletons") / f"{asset_id}_skeleton.json",
                Path("../storage/skeletons") / f"{asset_id}_skeleton.json", 
                Path("modules/video_studio/storage/skeletons") / f"{asset_id}_skeleton.json",
                Path("../modules/video_studio/storage/skeletons") / f"{asset_id}_skeleton.json"
            ]
            
            results = {}
            for i, path in enumerate(paths_to_test):
                results[f"path_{i}"] = {
                    "path": str(path),
                    "exists": path.exists(),
                    "absolute": str(path.absolute()) if path.exists() else None
                }
            
            return {
                "asset_id": asset_id,
                "current_dir": str(Path.cwd()),
                "paths_tested": results
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    @app.get("/api/studio/skeleton/{asset_id}")
    async def get_skeleton_data(asset_id: str):
        """Recupera dati skeleton per un asset specifico"""
        try:
            from pathlib import Path
            import json
            
            skeleton_file = Path("modules/video_studio/storage/skeletons") / f"{asset_id}_skeleton.json"
            
            if not skeleton_file.exists():
                # Prova con altri suffissi
                for suffix in ["_skeleton_FIXED.json", "_skeleton_REAL_TIMESTAMPS.json", "_skeleton_REAL.json"]:
                    alt_file = Path("modules/video_studio/storage/skeletons") / f"{asset_id}{suffix}"
                    if alt_file.exists():
                        skeleton_file = alt_file
                        break
                else:
                    raise HTTPException(status_code=404, detail="Skeleton data not found")
            
            with open(skeleton_file, 'r') as f:
                skeleton_data = json.load(f)
            
            return skeleton_data
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Skeleton data retrieval failed: {e}")
            raise HTTPException(status_code=500, detail=f"Skeleton data retrieval failed: {str(e)}")
    
    @app.get("/api/studio/thumbnail/{asset_id}")
    async def get_video_thumbnail(asset_id: str):
        """Genera thumbnail del video per la galleria"""
        try:
            from pathlib import Path
            from fastapi.responses import FileResponse
            import cv2
            
            video_path = Path("../storage/originals") / f"{asset_id}.mp4"
            thumbnail_path = Path("../storage/thumbnails") / f"{asset_id}.jpg"
            
            if not video_path.exists():
                raise HTTPException(status_code=404, detail="Video not found")
            
            # Genera thumbnail se non esiste
            if not thumbnail_path.exists():
                thumbnail_path.parent.mkdir(parents=True, exist_ok=True)
                
                cap = cv2.VideoCapture(str(video_path))
                ret, frame = cap.read()
                cap.release()
                
                if ret:
                    # Ridimensiona per thumbnail
                    height, width = frame.shape[:2]
                    new_width = 320
                    new_height = int(height * new_width / width)
                    frame_resized = cv2.resize(frame, (new_width, new_height))
                    
                    cv2.imwrite(str(thumbnail_path), frame_resized)
                else:
                    raise HTTPException(status_code=500, detail="Failed to generate thumbnail")
            
            return FileResponse(
                path=str(thumbnail_path),
                media_type="image/jpeg",
                filename=f"{asset_id}_thumb.jpg"
            )
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Thumbnail generation failed: {e}")
            raise HTTPException(status_code=500, detail=f"Thumbnail generation failed: {str(e)}")
    
    # Cleanup on shutdown
    @app.on_event("shutdown")
    async def shutdown_event():
        """Cleanup risorse al shutdown"""
        orchestrator.close()
        logger.info("Video Studio service shutdown")
    
    return app

def create_app(config: Dict[str, Any] = None) -> FastAPI:
    """Alias per create_video_studio_app per compatibilitÃ """
    if config is None:
        config = {
            'workflows_db': './data/workflows.db',
            'temp_dir': './temp',
            'output_dir': './output',
            'upload_dir': './uploads',
            'cors_origins': ['http://localhost:3000', 'http://localhost:3001']
        }
    return create_video_studio_app(config)

def main():
    """Main per avvio standalone"""
    config = {
        'workflows_db': './data/workflows.db',
        'temp_dir': './temp',
        'output_dir': './output',
        'upload_dir': './uploads',
        'cors_origins': ['http://localhost:3000', 'http://localhost:3001']
    }
    
    app = create_video_studio_app(config)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )

# Crea istanza globale dell'app per uvicorn
config = {
    'workflows_db': './data/workflows.db',
    'temp_dir': './temp',
    'output_dir': './output',
    'upload_dir': './uploads',
    'cors_origins': ['http://localhost:3000', 'http://localhost:3001', 'http://localhost:3100']
}
app = create_video_studio_app(config)

if __name__ == "__main__":
    main()

